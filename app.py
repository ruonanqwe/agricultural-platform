#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†œäº§å“å¸‚åœºä»·æ ¼ç®¡ç†å¹³å°
å‰åç«¯ä¸€ä½“åŒ–Webåº”ç”¨
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import json
import pandas as pd
from datetime import datetime, timedelta
import asyncio
import threading
import time
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from core.data_manager import get_data_manager
from core.crawler import get_crawler
from core.report_crawler import get_report_crawler
from core.report_analyzer import ReportAnalyzer
from core.scheduler import get_scheduler
from core.config import config

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="å†œäº§å“å¸‚åœºä»·æ ¼ç®¡ç†å¹³å°",
    description="å‰åç«¯ä¸€ä½“åŒ–çš„å¸‚åœºä»·æ ¼æ•°æ®ç®¡ç†ç³»ç»Ÿ",
    version="2.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
data_manager = get_data_manager()
crawler = get_crawler()
report_crawler = get_report_crawler()
scheduler = get_scheduler()
report_analyzer = ReportAnalyzer(data_manager)

# æ•°æ®æ¨¡å‹
class CrawlConfig(BaseModel):
    enabled: bool = True
    interval_minutes: int = 30
    provinces: List[str] = []

class SearchQuery(BaseModel):
    province: Optional[str] = None
    variety: Optional[str] = None
    market: Optional[str] = None
    date_from: Optional[str] = None
    date_to: Optional[str] = None
    limit: int = 100

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    return FileResponse("static/index.html")

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0"
    }

@app.get("/api/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = data_manager.get_statistics()
        crawler_status = crawler.get_status()
        scheduler_status = scheduler.get_status()
        
        return {
            "success": True,
            "data": {
                "data_stats": stats,
                "crawler_status": crawler_status,
                "scheduler_status": scheduler_status
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/search")
async def search_data(query: SearchQuery):
    """æœç´¢æ•°æ®"""
    try:
        results = data_manager.search_data(
            province=query.province,
            variety=query.variety,
            market=query.market,
            date_from=query.date_from,
            date_to=query.date_to,
            limit=query.limit
        )
        
        return {
            "success": True,
            "count": len(results),
            "data": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/data/latest")
async def get_latest_data(limit: int = 50):
    """è·å–æœ€æ–°æ•°æ®"""
    try:
        results = data_manager.get_latest_data(limit)
        return {
            "success": True,
            "count": len(results),
            "data": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/data/provinces")
async def get_provinces():
    """è·å–çœä»½åˆ—è¡¨"""
    try:
        provinces = data_manager.get_provinces()
        return {
            "success": True,
            "data": provinces
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/data/varieties")
async def get_varieties():
    """è·å–å“ç§åˆ—è¡¨"""
    try:
        varieties = data_manager.get_varieties()
        return {
            "success": True,
            "data": varieties
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/data/markets")
async def get_markets():
    """è·å–å¸‚åœºåˆ—è¡¨"""
    try:
        markets = data_manager.get_markets()
        return {
            "success": True,
            "data": markets
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/crawler/start")
async def start_crawler(background_tasks: BackgroundTasks):
    """å¯åŠ¨çˆ¬è™«"""
    try:
        background_tasks.add_task(crawler.start_crawling)
        return {"success": True, "message": "çˆ¬è™«å·²å¯åŠ¨"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/crawler/stop")
async def stop_crawler():
    """åœæ­¢çˆ¬è™«"""
    try:
        crawler.stop_crawling()
        return {"success": True, "message": "çˆ¬è™«å·²åœæ­¢"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/crawler/status")
async def get_crawler_status():
    """è·å–çˆ¬è™«çŠ¶æ€"""
    try:
        status = crawler.get_status()
        return {"success": True, "data": status}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/crawler/config")
async def update_crawler_config(config: CrawlConfig):
    """æ›´æ–°çˆ¬è™«é…ç½®"""
    try:
        crawler.update_config(config.model_dump())
        return {"success": True, "message": "é…ç½®å·²æ›´æ–°"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æŠ¥å‘Šçˆ¬è™«APIæ¥å£
@app.post("/api/report-crawler/start")
async def start_report_crawler(background_tasks: BackgroundTasks):
    """å¯åŠ¨æŠ¥å‘Šçˆ¬è™«"""
    try:
        background_tasks.add_task(report_crawler.start_crawling)
        return {"success": True, "message": "æŠ¥å‘Šçˆ¬è™«å·²å¯åŠ¨"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/report-crawler/stop")
async def stop_report_crawler():
    """åœæ­¢æŠ¥å‘Šçˆ¬è™«"""
    try:
        report_crawler.stop_crawling()
        return {"success": True, "message": "æŠ¥å‘Šçˆ¬è™«å·²åœæ­¢"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/report-crawler/status")
async def get_report_crawler_status():
    """è·å–æŠ¥å‘Šçˆ¬è™«çŠ¶æ€"""
    try:
        status = report_crawler.get_status()
        return {"success": True, "data": status}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/report-crawler/crawl-once")
async def crawl_reports_once(background_tasks: BackgroundTasks, full_crawl: bool = True):
    """æ‰§è¡Œä¸€æ¬¡æŠ¥å‘Šçˆ¬å–

    Args:
        full_crawl: æ˜¯å¦è¿›è¡Œå®Œæ•´çˆ¬å–ï¼ˆæ‰€æœ‰é¡µé¢ï¼‰
    """
    try:
        # ä¸´æ—¶è®¾ç½®çˆ¬å–æ¨¡å¼
        original_config = report_crawler.config.get('full_crawl', True)
        report_crawler.config['full_crawl'] = full_crawl

        background_tasks.add_task(report_crawler.crawl_once)

        # æ¢å¤åŸå§‹é…ç½®
        report_crawler.config['full_crawl'] = original_config

        crawl_mode = "å®Œæ•´çˆ¬å–" if full_crawl else "å¿«é€Ÿçˆ¬å–"
        return {"success": True, "message": f"å¼€å§‹æ‰§è¡Œå•æ¬¡æŠ¥å‘Šçˆ¬å–ï¼ˆ{crawl_mode}ï¼‰"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/reports/latest")
async def get_latest_reports(limit: int = 20, page: int = 1, report_type: str = "all"):
    """è·å–æœ€æ–°æŠ¥å‘Š

    Args:
        limit: æ¯é¡µæ•°é‡
        page: é¡µç 
        report_type: æŠ¥å‘Šç±»å‹ (all, daily, monthly, yearly)
    """
    try:
        reports_file = data_manager.data_dir / "analysis_reports.csv"

        if not reports_file.exists():
            return {
                "success": True,
                "count": 0,
                "data": [],
                "total": 0,
                "page": page,
                "total_pages": 0,
                "report_type": report_type
            }

        import pandas as pd
        df = pd.read_csv(reports_file, encoding='utf-8-sig')

        if df.empty:
            return {
                "success": True,
                "count": 0,
                "data": [],
                "total": 0,
                "page": page,
                "total_pages": 0,
                "report_type": report_type
            }

        # æ¸…ç†æ•°æ®
        df = df.fillna('')

        # æ ¹æ®æŠ¥å‘Šç±»å‹è¿‡æ»¤
        if report_type != "all":
            if report_type == "daily":
                df = df[df['æŠ¥å‘Šç±»å‹'] == 'å†œäº§å“æ‰¹å‘å¸‚åœºä»·æ ¼æ—¥æŠ¥']
            elif report_type == "monthly":
                df = df[df['æŠ¥å‘Šç±»å‹'] == 'å†œä¸šåˆ†ææŠ¥å‘Š']
            elif report_type == "yearly":
                # ç›®å‰æ²¡æœ‰å¹´æŠ¥ï¼Œé¢„ç•™æ¥å£
                df = df[df['æŠ¥å‘Šç±»å‹'].str.contains('å¹´æŠ¥', na=False)]

        # æŒ‰çˆ¬å–æ—¶é—´æ’åº
        if 'çˆ¬å–æ—¶é—´' in df.columns:
            df = df.sort_values('çˆ¬å–æ—¶é—´', ascending=False)

        # è®¡ç®—åˆ†é¡µ
        total_records = len(df)
        total_pages = (total_records + limit - 1) // limit
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit

        # è·å–å½“å‰é¡µæ•°æ®
        page_df = df.iloc[start_idx:end_idx]

        # è½¬æ¢ä¸ºå­—å…¸å¹¶æ¸…ç†æ•°å€¼
        records = page_df.to_dict('records')

        return {
            "success": True,
            "count": len(records),
            "data": records,
            "total": total_records,
            "page": page,
            "total_pages": total_pages,
            "limit": limit,
            "report_type": report_type
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/reports/stats")
async def get_report_stats():
    """è·å–æŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯"""
    try:
        reports_file = data_manager.data_dir / "analysis_reports.csv"

        if not reports_file.exists():
            return {
                "total": 0,
                "daily_count": 0,
                "monthly_count": 0,
                "yearly_count": 0,
                "types": []
            }

        import pandas as pd
        df = pd.read_csv(reports_file, encoding='utf-8-sig')

        if df.empty:
            return {
                "total": 0,
                "daily_count": 0,
                "monthly_count": 0,
                "yearly_count": 0,
                "types": []
            }

        # ç»Ÿè®¡å„ç±»å‹æŠ¥å‘Šæ•°é‡
        daily_count = len(df[df['æŠ¥å‘Šç±»å‹'] == 'å†œäº§å“æ‰¹å‘å¸‚åœºä»·æ ¼æ—¥æŠ¥'])
        monthly_count = len(df[df['æŠ¥å‘Šç±»å‹'] == 'å†œä¸šåˆ†ææŠ¥å‘Š'])
        yearly_count = len(df[df['æŠ¥å‘Šç±»å‹'].str.contains('å¹´æŠ¥', na=False)])

        # è·å–æ‰€æœ‰æŠ¥å‘Šç±»å‹
        types = df['æŠ¥å‘Šç±»å‹'].value_counts().to_dict()

        return {
            "total": len(df),
            "daily_count": daily_count,
            "monthly_count": monthly_count,
            "yearly_count": yearly_count,
            "types": types
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/reports/export")
async def export_reports():
    """å¯¼å‡ºæŠ¥å‘Šæ•°æ®"""
    try:
        reports_file = data_manager.data_dir / "analysis_reports.csv"

        if not reports_file.exists():
            raise HTTPException(status_code=404, detail="æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")

        return FileResponse(
            reports_file,
            media_type='application/octet-stream',
            filename=f"analysis_reports_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/export/csv")
async def export_csv(
    province: Optional[str] = None,
    variety: Optional[str] = None,
    market: Optional[str] = None,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None
):
    """å¯¼å‡ºCSVæ–‡ä»¶"""
    try:
        file_path = data_manager.export_csv(
            province=province,
            variety=variety,
            market=market,
            date_from=date_from,
            date_to=date_to
        )
        
        return FileResponse(
            file_path,
            media_type='application/octet-stream',
            filename=f"market_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/dashboard/trends")
async def get_dashboard_trends(days: int = 30):
    """è·å–ä»ªè¡¨æ¿è¶‹åŠ¿æ•°æ®"""
    try:
        # è·å–ä»·æ ¼æ•°æ®è¶‹åŠ¿
        price_trends = await get_price_trends(days)

        # è·å–æŠ¥å‘Šæ•°æ®è¶‹åŠ¿
        report_trends = await get_report_trends()

        # è·å–å…³é”®æŒ‡æ ‡
        key_metrics = await get_key_metrics()

        return {
            "success": True,
            "data": {
                "price_trends": price_trends,
                "report_trends": report_trends,
                "key_metrics": key_metrics,
                "last_update": datetime.now().isoformat(),
                "time_range": f"{days}å¤©"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def get_price_trends(days: int = 30):
    """è·å–ä»·æ ¼è¶‹åŠ¿æ•°æ®"""
    try:
        # ä»CSVæ–‡ä»¶è·å–æŒ‡å®šå¤©æ•°çš„ä»·æ ¼æ•°æ®
        csv_file = data_manager.data_dir / "market_prices.csv"

        import pandas as pd

        real_data = []
        if csv_file.exists():
            df = pd.read_csv(csv_file, encoding='utf-8-sig')

            if not df.empty:
                # æ¸…ç†æ•°æ®
                df = df.fillna(0)

                # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—å¹³å‡ä»·æ ¼
                if 'äº¤æ˜“æ—¥æœŸ' in df.columns and 'å¹³å‡ä»·' in df.columns:
                    df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'], errors='coerce')
                    df = df.dropna(subset=['äº¤æ˜“æ—¥æœŸ'])

                    # è·å–æŒ‡å®šå¤©æ•°çš„æ•°æ®
                    recent_date = df['äº¤æ˜“æ—¥æœŸ'].max()
                    start_date = recent_date - pd.Timedelta(days=days)
                    recent_df = df[df['äº¤æ˜“æ—¥æœŸ'] >= start_date]

                    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—å¹³å‡ä»·æ ¼
                    daily_avg = recent_df.groupby('äº¤æ˜“æ—¥æœŸ')['å¹³å‡ä»·'].mean().reset_index()
                    daily_avg = daily_avg.sort_values('äº¤æ˜“æ—¥æœŸ')

                    for _, row in daily_avg.iterrows():
                        real_data.append({
                            'äº¤æ˜“æ—¥æœŸ': row['äº¤æ˜“æ—¥æœŸ'].strftime('%Y-%m-%d'),
                            'å¹³å‡ä»·': float(row['å¹³å‡ä»·'])
                        })

        # åªè¿”å›çœŸå®æ•°æ®ï¼Œä¸ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®

        return real_data

    except Exception as e:
        logger.error(f"è·å–ä»·æ ¼è¶‹åŠ¿å¤±è´¥: {e}")
        return []

async def get_report_trends():
    """è·å–æŠ¥å‘Šè¶‹åŠ¿æ•°æ®"""
    try:
        # ä»CSVæ–‡ä»¶è·å–æŠ¥å‘Šæ•°æ®
        reports_file = data_manager.data_dir / "analysis_reports.csv"
        if not reports_file.exists():
            return []

        import pandas as pd
        df = pd.read_csv(reports_file, encoding='utf-8-sig')

        if df.empty:
            return []

        # æŒ‰æŠ¥å‘Šç±»å‹ç»Ÿè®¡
        type_counts = df['æŠ¥å‘Šç±»å‹'].value_counts().to_dict()

        # æŒ‰æ—¥æœŸç»Ÿè®¡æŠ¥å‘Šæ•°é‡
        if 'çˆ¬å–æ—¶é—´' in df.columns:
            df['çˆ¬å–æ—¶é—´'] = pd.to_datetime(df['çˆ¬å–æ—¶é—´'], errors='coerce')
            df = df.dropna(subset=['çˆ¬å–æ—¶é—´'])
            df['æ—¥æœŸ'] = df['çˆ¬å–æ—¶é—´'].dt.date

            daily_counts = df.groupby('æ—¥æœŸ').size().reset_index(name='æŠ¥å‘Šæ•°é‡')
            daily_counts['æ—¥æœŸ'] = daily_counts['æ—¥æœŸ'].astype(str)

            return {
                "type_distribution": type_counts,
                "daily_counts": daily_counts.to_dict('records')
            }

        return {"type_distribution": type_counts, "daily_counts": []}
    except Exception as e:
        logger.error(f"è·å–æŠ¥å‘Šè¶‹åŠ¿å¤±è´¥: {e}")
        return {}

async def get_key_metrics():
    """è·å–å…³é”®æŒ‡æ ‡"""
    try:
        metrics = {}

        # ä»·æ ¼æŒ‡æ ‡
        csv_file = data_manager.data_dir / "market_prices.csv"
        if csv_file.exists():
            import pandas as pd
            df = pd.read_csv(csv_file, encoding='utf-8-sig')

            if not df.empty:
                df = df.fillna(0)

                # è®¡ç®—ä»·æ ¼æŒ‡æ ‡
                if 'å¹³å‡ä»·' in df.columns:
                    metrics['avg_price'] = float(df['å¹³å‡ä»·'].mean())
                    metrics['max_price'] = float(df['å¹³å‡ä»·'].max())
                    metrics['min_price'] = float(df['å¹³å‡ä»·'].min())

                # è®¡ç®—ä»·æ ¼å˜åŒ–è¶‹åŠ¿
                if 'äº¤æ˜“æ—¥æœŸ' in df.columns and 'å¹³å‡ä»·' in df.columns:
                    df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'], errors='coerce')
                    df = df.dropna(subset=['äº¤æ˜“æ—¥æœŸ'])
                    df = df.sort_values('äº¤æ˜“æ—¥æœŸ')

                    if len(df) >= 2:
                        recent_price = df.iloc[-1]['å¹³å‡ä»·']
                        previous_price = df.iloc[-2]['å¹³å‡ä»·']
                        if previous_price > 0:
                            price_change = ((recent_price - previous_price) / previous_price) * 100
                            metrics['price_change_percent'] = round(price_change, 2)

        # æŠ¥å‘ŠæŒ‡æ ‡
        reports_file = data_manager.data_dir / "analysis_reports.csv"
        if reports_file.exists():
            import pandas as pd
            df = pd.read_csv(reports_file, encoding='utf-8-sig')

            if not df.empty:
                metrics['total_reports'] = len(df)
                metrics['report_types'] = df['æŠ¥å‘Šç±»å‹'].nunique() if 'æŠ¥å‘Šç±»å‹' in df.columns else 0

        return metrics
    except Exception as e:
        logger.error(f"è·å–å…³é”®æŒ‡æ ‡å¤±è´¥: {e}")
        return {}

@app.get("/api/dashboard/data")
async def get_dashboard_data():
    """è·å–ä»ªè¡¨ç›˜æ•°æ®"""
    try:
        dashboard_data = report_analyzer.get_dashboard_data()
        return dashboard_data
    except Exception as e:
        logger.error(f"è·å–ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/dashboard/trends")
async def get_trends_data(category: str = "all"):
    """è·å–è¶‹åŠ¿æ•°æ®

    Args:
        category: æ•°æ®ç±»åˆ« (all, price_index, vegetables, fruits, meat, aquatic)
    """
    try:
        dashboard_data = report_analyzer.get_dashboard_data()

        if not dashboard_data.get("success"):
            return dashboard_data

        trends_data = dashboard_data["data"]

        if category == "all":
            return {"success": True, "data": trends_data}
        elif category == "price_index":
            return {"success": True, "data": {"price_index_trend": trends_data.get("price_index_trend", [])}}
        elif category in ["vegetables", "fruits", "meat", "aquatic"]:
            category_trends = trends_data.get("category_price_trends", {})
            return {"success": True, "data": {category: category_trends.get(category, [])}}
        else:
            return {"success": False, "error": "æ— æ•ˆçš„æ•°æ®ç±»åˆ«"}

    except Exception as e:
        logger.error(f"è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    print("ğŸš€ å†œäº§å“å¸‚åœºä»·æ ¼ç®¡ç†å¹³å°å¯åŠ¨ä¸­...")
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager.initialize()
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    
    print("âœ… å¹³å°å¯åŠ¨å®Œæˆ!")
    print(f"ğŸ“Š ç®¡ç†ç•Œé¢: http://localhost:8000")
    print(f"ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    print("ğŸ›‘ å¹³å°æ­£åœ¨å…³é—­...")
    
    # åœæ­¢çˆ¬è™«
    crawler.stop_crawling()
    
    # åœæ­¢è°ƒåº¦å™¨
    scheduler.stop()
    
    print("âœ… å¹³å°å·²å®‰å…¨å…³é—­")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
